% !TEX root = main.tex
\documentclass[12pt]{article}

% Preamble (packages + macros)
\input{preamble/packages}
\input{preamble/macros}
\setcounter{tocdepth}{1}

\begin{document}
\author{}

% Title
\title{
    \vspace{2cm} 
    {\Large DS-GA 1014}\\[0.5em]
    {\Large Optimization and Computational Linear Algebra}\\[0.5em]
    {\large Andrew Liao}\\[0.5em]
    {\large \today}\\[0.5em]
}
\date{} 
\maketitle
\newpage

% ---- Abstract ----
\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

This is a graduate level, proof-based linear algebra course taught by \href{https://florentinguth.github.io/}{Florentin Guth} at NYU Center for Data Science. 
It covers the basics of optimization and computational linear algebra in Data Science applications, with 66\% of content being linear algebra and 33\% being optimization.
This course was taken in Fall of 2025, with the date in title page indicating date last updated. 
\vspace{5cm}

\begin{center}
    \includegraphics[width=\textwidth]{LA_opt_cover.png}
\end{center}

\vspace{10em}
\noindent Image generated with Nano Banana Pro with prompt: "cool gradient descent figure".
\newpage

% Table of contents
\tableofcontents
\newpage

% ---- Lectures ----
\input{lectures/vector_spaces.tex}
\newpage
\input{lectures/linear_transformations}
\newpage
\input{lectures/matrix_rank}
\newpage
\input{lectures/norms_ip_orth}
\newpage
\input{lectures/orth_matrices}
\newpage
\input{lectures/eigen_markov}
\newpage
\input{lectures/spectral_pca}
\newpage
\input{lectures/svd_graphs}
\newpage
\input{lectures/convexity}
\newpage
\input{lectures/linear_regression}
\newpage
\input{lectures/optimality_conditions}
\newpage
\input{lectures/gradient_descent}

\end{document}