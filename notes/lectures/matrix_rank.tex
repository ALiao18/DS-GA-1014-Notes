% !TEX root = ../main.tex
\section{Matrix Rank}

\begin{idea}
\textbf{Motivation:} Consider a dataset $x_{1},\dots,x_{n} \in \mathbb{R}^{d}$. What is its dimensionality?
There are many notions of dimensionality. The rank is one of them.
\end{idea}

\subsection{The Rank}

\begin{definition}[Rank of a Family]
    We can define the rank of a family $x_{1},\dots,x_{k}$ of vectors in $\mathbb{R}^{n}$ as the dimension of its span.
    \[ rank(x_{1},\dots,x_{k})\stackrel{\text{def}}{=}dim(Span(x_{1},\dots,x_{k})) \]
\end{definition}

\begin{definition}[Rank of a Matrix]
    Let $M \in \mathbb{R}^{n \times m}$ and $c_{1},\dots,c_{m} \in \mathbb{R}^{n}$ be its columns.
    \begin{align}
    rank(M)&\stackrel{\text{def}}{=}rank(c_{1},\dots,c_{m}) \\
    &=dim(\mathrm{Im}(M)) = dim(Span(c_{1},\dots,c_{m}))
    \end{align}
\end{definition}

\noindent $rank(M) \leq \min(m, n)$.

\subsubsection*{Examples}
\begin{enumerate}
    \item $rank(Id_{n})=dim(\mathbb{R}^{n})=n$.
    \item $rank(\begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix})=2$ (vectors are linearly independent).
    \item $rank(\begin{pmatrix} 1 & 2 & 1 \\ 0 & 0 & 1 \end{pmatrix}) \leq 2$.
\end{enumerate}

\begin{proposition}[Rank of columns = Rank of rows]
    Let $r_{1},\dots,r_{n}$ be the rows and $c_{1},\dots,c_{m}$ be the columns of $M$.
    \[ rank(r_{1},\dots r_{n})=rank(c_{1},\dots c_{m})= rank(M) \]
\end{proposition}

\subsection{The Rank-Nullity Theorem}
\begin{theorem}[Rank-Nullity]
    Let $L: \mathbb{R}^{m}\to \mathbb{R}^{n}$ be a linear transformation.
    Then:
    \[ rank(L)+dim(Ker(L))=m \]
\end{theorem}

\begin{proof}
    Let $v_{1},\dots v_{k}$ be a basis of $Ker(L)$ ($k=dim(Ker(L))$). Complete it with $v_{k+1},\dots,v_{m}$ into a basis of $\mathbb{R}^{m}$.
    \begin{align}
    \mathrm{Im}(L)&=\{ L(x),x \in \mathbb{R}^{m} \} \\
                  &=\{ \alpha_{k+1}L(v_{k+1})+\dots+\alpha_{m}L(v_{m}) \mid \alpha_{k+1},\dots,\alpha_{m} \in \mathbb{R} \} \\
                  &=Span(L(v_{k+1}),\dots,L(v_{m}))
    \end{align}
    To show $L(v_{k+1}),\dots,L(v_{m})$ are linearly independent:
    Assume $\sum_{i=k+1}^m \alpha_i L(v_i) = 0$.
    Then $L(\sum \alpha_i v_i) = 0$, so $\sum \alpha_i v_i \in Ker(L)$.
    This implies $\sum_{i=k+1}^m \alpha_i v_i = \sum_{j=1}^k \beta_j v_j$.
    Since $v_1, \dots, v_m$ is a basis, all coefficients must be zero.
    Thus $L(v_{k+1}),\dots,L(v_{m})$ are independent.
    So $rank(L) = m - k = m - dim(Ker(L))$.
\end{proof}

\subsection{Inequalities}
Let $A \in \mathbb{R}^{n \times m}$ and $B \in \mathbb{R}^{m \times k}$.
\begin{enumerate}
    \item $rank(A)\leq \min(n, m)$.
    \item $rank(AB) \leq \min(rank(A), rank(B))$.
\end{enumerate}

\begin{proof}
    \textbf{Showing $rank(AB)\leq rank(A)$:}
    $\mathrm{Im}(AB)=\{ ABx, x \in \mathbb{R}^{k} \} \subseteq \mathrm{Im}(A)$.
    Since the subspace is contained, the dimension is smaller or equal.

    \textbf{Showing $rank(AB)\leq rank(B)$:}
    We show $Ker(B) \subseteq Ker(AB)$.
    Let $x \in Ker(B) \implies Bx=0 \implies ABx=A(0)=0 \implies x \in Ker(AB)$.
    Since $Ker(B) \subseteq Ker(AB)$, $dim(Ker(B)) \leq dim(Ker(AB))$.
    By Rank-Nullity: $rank(AB) = k - dim(Ker(AB)) \leq k - dim(Ker(B)) = rank(B)$.
\end{proof}

\subsection{Rank of invertible matrices}
\begin{theorem}
    Let $M \in \mathbb{R}^{n \times n}$. The following points are equivalent:
    \begin{enumerate}
        \item $M$ is invertible.
        \item $rank(M)=n$.
        \item $Ker(M)=\{ 0 \}$.
        \item $\forall y \in \mathbb{R}^{n}, \exists \text{ unique } x \in \mathbb{R}^{n} \text{ s.t. } Mx=y$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    \textbf{$1 \rightarrow 2$:} Let $y \in \mathbb{R}^{n}$. $y=M(M^{-1}y)$, so $y \in \mathrm{Im}(M)$. Thus $\mathrm{Im}(M)=\mathbb{R}^n$, so $rank(M)=n$.
    \textbf{$2 \rightarrow 3$:} From Rank-Nullity, $dim(Ker(M))=n-rank(M)=0$.

    \textbf{$3 \rightarrow 4$:}
    Existence: $dim(\mathrm{Im}(M)) = n - dim(Ker(M)) = n$, so $\mathrm{Im}(M)=\mathbb{R}^n$.
    Uniqueness: If $Mx=Mx'$, then $M(x-x')=0 \implies x-x' \in Ker(M)=\{0\} \implies x=x'$.
    \textbf{$4 \rightarrow 1$:} Property 4 implies $M$ is a bijection. Construct $M^{-1}$ using the unique pre-images of the canonical basis.
\end{proof}

\subsection{Transpose of a matrix}
Let $M \in \mathbb{R}^{ n \times m}$.
We define its transpose $M^{\top}\in \mathbb{R}^{m \times n }$ by $M^{\top}_{i,j}=M_{j,i}$.
\begin{itemize}
    \item $\forall A \in \mathbb{R}^{n \times m}, rank(A)=rank(A^{\top})$.
    \item $(AB)^{\top}=B^{\top}A^{\top}$.
    \item A matrix is \textbf{symmetric} if $A = A^{\top}$.
\end{itemize}