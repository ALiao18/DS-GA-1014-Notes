# table of contents
1. eigenvalues and eigenvectors
2. markov chains
---
# eigenvalues and eigenvectors
## definitions
### eigenvalues and eigenvectors. 
Let $A \in \mathbb{R}^{n \times n}$. A non-zero vector $v \in \mathbb{R}^{n}$ is said to be an eigenvector of $A$ if $\exists \lambda \in \mathbb{R} \text{ s.t. } Av=\lambda v$. The scalar $\lambda$ is called the eigenvalue of $A$ associated to $v$. 

properties 
1. $\forall \alpha \in \mathbb{R}, \alpha\lambda$ is an eigenvalue of the matrix $\alpha A$. The eigenvector is unchanged.  
	1. $(\alpha A)x=(\alpha \lambda)x$
2. $\forall \alpha \in \mathbb{R}, \lambda + \alpha$ is an eigenvalue of the matrix $A+\alpha Id$. The eigenvector is unchanged. 
	1. $A+\alpha Idx=Ax+\alpha x = (\lambda+\alpha)x$
3. $\forall k \in \mathbb{N}, \lambda^k$ is an eigenvalue of the matrix $A^k$. The eigenvector is unchanged. 
	1. $A^kx=A^{k-1}Ax=\lambda A^{k-1}x=\lambda^{2}A^{k-2}x=\dots=\lambda^kx$
4. If $A$ is invertible then $\frac{1}{\lambda}$ is an eigenvalue of the matrix inverse $A^{-1}$ and $x$ is an associated eigenvector. 
	1. this also means that an invertible matrix cannot have a zero eigenvalue. This is because any invertible matrix has a trivial kernel.

### eigenspaces
If $\lambda \in \mathbb{R}$ is an eigenvalue of $A \in \mathbb{R}^{n \times n}$, the set
$$
\begin{align}
E_{\lambda}(A)=\{ x \in \mathbb{R}^{n}|Ax=\lambda x \}=Ker(A-\lambda Id)
\end{align}
$$
is called the eigenspace of $A$ associated to $\lambda$. The dimension of $E_{\lambda}(A)$ is called the multiplicity of the eigenvalue $\lambda$. 
$$
\begin{align}
Ax=\lambda x &\iff (A-\lambda Id)x = 0 \\
             &\iff x \in Ker(A-\lambda Id)
\end{align}
$$
To determine eigenvalues and eigenvectors, solve $(A-\lambda Id)x=0$ over $x \in \mathbb{R}^{n}$ for arbitrary $\lambda \in \mathbb{R}$.   

### spectrum
The set of all eigenvalues of $A$ is called the *spectrum* of $A$ and denoted by $Sp(A)=\{ \lambda \in \mathbb{R} \text{ s.t. } \lambda \text{ is an eigenvalue of A} \}$
Theorem: A $n \times n$ matrix $A$ admits at most $n$ different eigenvalues

#### proof Sp(A)$\leq$ n:
Let $v_{1},\dots,v_{k}$ be eigenvectors of $A$ corresponding to the eigenvalues $\lambda_{1},\dots,\lambda_{k}$. If the $\lambda_{i}$ are all distinct such that $\lambda_{i} \neq \lambda_{j} \forall i \neq j$, then the vectors $v_{1},\dots,v_{k}$ are linearly independent. 

Let $\alpha_{1},\dots,\alpha+k \in \mathbb{R} \text{ s.t. } \sum_{i=1}^{k}\alpha_{i}v_{i}=0$
Then $0=\sum_{i=1}^{k}\alpha_{i}Av_{i}=\sum_{i=1}^{k}\alpha_{i}\lambda_{i}v_{i}$
Then $0=\sum_{i=1}^{k}\alpha_{i}\lambda_{i}Av_{i}=\sum_{i=1}^{k}\alpha_{i}\lambda_{i}^{2}v_{i}$
$\forall j \in \mathbb{N}, \sum_{i=1}^{k}\alpha_{i}\lambda_{i}^jv_{i}=0$
$\sum_{i=1}^{k}\alpha_{i}\left( \sum_{j=0}^{n-1}\beta_{j}\lambda_{i}^j \right)v_{i}=0$

Thus for any polynomial P, $\sum_{i=1}^{k}\alpha_{i}P(\lambda_{i})v_{i}=0$.

consider $P(x)=(X-\lambda_{2})(X-\lambda_{3})\dots(X-\lambda_{k})$
Then $P{(\lambda_{2})}=\dots=P(\lambda_{k})=0$
And $P(\lambda_{1})=(\lambda_{1}-\lambda_{2})\dots(\lambda_{1}-\lambda_{k}) \neq 0$
Then $\alpha_{1}P(\lambda_{1})v_{1}=0$ then $\alpha_{1}=0$
Similarly, for all $i \in \{ 1,\dots,m \}, \alpha_{i}=0$
This shows that $v_{1},\dots,v_{k}$ is linearly independent. 

**Theorem:** Let $A \in \mathbb{R}^{n \times n}$. If $\lambda_{1},\dots,\lambda_{k}$ are distinct eigenvalues of $A$ of multiplicities $m_{1},..,m_{k}$ respectively, then $m_{1}+\dots+m_{k}\leq n$.

# markov chains
Whenever you have a graph of nodes and edges, you can encode it as an adjacency matrix. 

A matrix $P \in \mathbb{R}^{n \times n}$ is said to be stochastic if
1. $P_{i,j} \geq 0 \quad\forall 1\leq i, j \leq n$
2. $\sum_{i=1}^{n}P_{i,j}=1\quad \forall 1 \leq j \leq n$

## probability vectors
At time $t$, we have a probability distribution over states. $\mathbb{P}[\text{state at time t=i}]_{i=1,\dots,n}$. This is a vector $x_{t} \in \mathbb{R}^{n}$. $x_{t}$ is a probability vector $x \in \nabla_{n}$. $\nabla_{n}$ is the set of probability vectors. 
$x$ satisfies the basic properties of probability distributions:
1. $(x_{t})_{i} \geq 0 \quad \forall i \in \{ 1,\dots,n \}$ non-negative
2. $\sum_{i=1}^{n}(x_{t})_{i}=1$ total probability = 1

## the key equation
Proposition:
For all $t \geq 0$
$$
\begin{align} \\
x^{t+1}=Px^t \\
\therefore x^t=P^tx^0
\end{align} \\
$$
We can see that
$$
\begin{align*}
(x^{t+1})_{i}&=\mathbb{P}[\text{state at time } t+1=i] \\
              &=\sum_{j=1}^{n}\mathbb{P}[\text{state at time t+1=i}|\text{state at time }t=j] \\
              &=\sum_{j=1}^{n}P_{ij}(x^t)_{j} \\
              &=(Px^t)_i \\
x^1=Px^0, x^{2}&=Px^1=P^{2}x^0, x^{3}=P^{3}x^0,\dots 
\end{align*}
$$

We can think about the long term behavior, or the limit distribution as 
$x^{t+1}=Px^t$
Maybe $x^t \stackrel{t \rightarrow \infty}{\longrightarrow} \mu$ limit distribution such as $\mu$ is also a probability vector. 
So that when $t \longrightarrow \infty: \mu = P\mu$

## invariant measure
We can define a vector $\mu \in \nabla_{n}$ as an invariant measure for the transition matrix $P$ if
$$
\begin{align}
\mu=\mu P
\end{align}
$$
that is, $\mu$ is a **left eigenvector** of $P$ associated with the eigenvalue 1.
It describes the **long-run frequency of visits** to each state _if_ such a limiting distribution exists and the chain converges to it.
### properties
1. Existence:
	1. every finite Markov chain has at least 1 stationary measure
	2. lack of a stationary measure can only occur if there is infinite state space or non-positive recurrent state spaces. 
2. uniqueness:
	1. there exists a unique stationary measure if chain is irreducible and aperiodic (Perron Frobenius Theorem)
3. convergence:
	1. having a stationary measure does not guarantee convergence. 
## Perron-Frobenius Theorem

Basically: 
1. each state can get to any other state with finite steps
2. aperiodic

Let $P$ be a stochastic matrix such that there exists $k \geq 1$ such that all the entries of $P^k$ are strictly positive, then the following holds:
1. 1 is an eigenvalue of $P$ and there exists an eigenvector $\mu \in \nabla_{n}$ associated to 1.
	1. $\mu=P\mu$
2. The eigenvalue has multiplicity 1: $Ker(P-Id)=Span(\mu)$
	1. $\mu$ is unique
3. All other eigenvalues $\lambda$ of $P$ satisfy $\lvert \lambda \rvert < 1$
4. $\forall x \in \nabla_{n}, P^tx \stackrel{t\rightarrow \infty}{\longrightarrow} \mu$.

Note that this is really restrictive and there are cases where these do not satisfy but the results are still true! 

### consequence:
corollary:
Let $P$ be a stochastic matrix $\text{ s.t. } \exists k \geq 1 \text{ s.t. }$ all entries of $P^k > 0$.
Then there exists a unique invariant measure $\mu$ and for all initial condition $x^0 \in \nabla_{n}$,
$$
\begin{align}
x^t=p^tx^0 \stackrel{t \rightarrow \infty}{\longrightarrow} \mu
\end{align}
$$
## PageRank: Ordering the Web
Goal: find interesting pages
Idea: interesting pages have links going towards them from interesting pages themselves

1. naive attempt
	1. rank according to incoming links
2. random surfer
	1. suppose someone clicks on a random link every single time. Look at what pages they spend most of their time on. That is probably the most interesting page. 

This defines a Markov chain of transition matrix:
$$
P_{i,j} =
\begin{cases}
\frac{1}{\deg(j)}, & \text{if there is a link } j \to i,\\[6pt]
0, & \text{otherwise.}
\end{cases}
$$
After a long time, the surfer is more likely to be on an important webpage. 
If the $\mu$ is the invariant measure of $P$ provided $P$ satisfies Perron-Frobenius, we take
$\mu_{i}=\text{"importance" of webpage i}$

### random spectator
Imagine the following "random spectator":
- At time $t$, the spectator believes that player $j$ is the best: $X_{t}=j$
- Then, they pick a game of player $j$ uniformly at random:
	- if player $j$ wins, then the spectator still believes that $j$ is the best: $X_{t+1}=j$
	- otherwise, they change their minds to now believe that $i$ who beat $j$ is the best: $X_{t+1}=i$
- With probability $\alpha$, the spectator picks a new favorite player uniformly at random. 

This defines a transition matrix $P$. We rank the players according to the stationary distribution $\mu$ of $M=(1-\alpha)P+\frac{\alpha}{N}J$

If we apply this onto famous tennis players, we see the distribution has a much longer tail compared to the naive ranking. This is because who you played against is now factored in whereas it wasn't in the naive ranking.  